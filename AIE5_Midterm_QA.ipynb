{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnmx57dxWcK2c2VLPGMCl9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabesink/AIE5/blob/main/AIE5_Midterm_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Defining your Problem and Audience\n",
        "    a. Write a succinct 1-sentence description of the problem\n",
        "    b. Write 1-2 paragraphs on why this is a problem for your specific user\n",
        "\n",
        "### Answers\n",
        "[a] Structural analysis engineers struggle with a lack of knowledge and expertise in effectively using Magnesium alloys (Mg Alloys) for the manufacturing of automotive structural components.\n",
        "\n",
        "[b] The inability of structural analysis engineers to effectively utilize Magnesium alloys (Mg Alloys) for manufacturing automotive components is a significant issue due to the material's unique properties. Magnesium alloys are lightweight, which can lead to significant fuel efficiency and performance improvements in vehicles. However, without proper knowledge and expertise, engineers may struggle to leverage these benefits in the context of automotive design, leading to suboptimal component performance, potential safety issues, and increased costs. Misapplication of the material could result in failure to achieve the desired strength-to-weight ratio, affecting the overall vehicle performance and durability.\n",
        "\n",
        "Moreover, the complexity of working with Magnesium alloys requires a deep understanding of their behavior under various stress conditions, fatigue resistance, and response to different manufacturing processes. Without this specialized knowledge, engineers may not be able to fully exploit the advantages of Mg Alloys, such as improved energy efficiency and reduced carbon footprint. This gap in expertise can hinder innovation and prevent companies from staying competitive in the rapidly advancing automotive industry, which increasingly demands high-performance, eco-friendly materials.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Task 2: Propose a Solution\n",
        "    a. Write 1-2 paragraphs on your proposed solution.  How will it look and feel to the user?\n",
        "    b. Describe the tools you plan to use in each part of your stack.  Write one sentence on why you made each tooling choice.\n",
        "\n",
        "[a]  The proposed solution is an expert AI system that functions as an intelligent answer engine designed to assist structural analysis engineers in real-time. This AI-powered system acts as a vast knowledge repository, providing engineers with instant access to expert-level insights on Magnesium alloys (Mg Alloys), including appropriate processing conditions, structural properties, and information from past projects. Engineers can simply ask the AI system any question related to Mg Alloys, whether it's about material behavior, design considerations, or optimal manufacturing techniques. The system will quickly deliver tailored, accurate responses, drawing from a rich database of both historical proprietary data and the latest research.\n",
        "\n",
        "To the user, this solution will feel like an intuitive, highly responsive assistant that simplifies the decision-making process. Engineers can focus on component design and optimization, knowing that they have a reliable, expert source of information at their fingertips, without the need for time-consuming research or trial and error. The system will be integrated into the engineers’ workflow, allowing them to seamlessly interact with it through a user-friendly interface. The ease of accessing relevant data and guidance will streamline operations, enhance productivity, and ultimately result in faster, more effective decisions when working with Magnesium alloys in automotive structural components.\n",
        "\n",
        "[b] LLM: GPT-4o-mini will be used for easy deployment and scalability. llama3.2 will be used for running locally to ensure proprietary data is not leaked.\n",
        "    Embedding Model: Snowflake/snowflake-arctic-embed-l - used for the embedding model as it is a fast and efficient embedding model that can be hosted locally.\n",
        "    Orchestration: LangChain/LangGraph - used for the agentic pipeline and the RAG pipelines since it is a powerful and flexible framework for building and orchestrating AI workflows.\n",
        "    Vector Store: Qdrant - used for the vector store as it can be easily integrated with the LangChain framework, and because it can be hosted locally and scale well.\n",
        "    Monitoring: Langsmith will be used to monitor the pipeline and the agentic pipeline. For local deployment, Langfuse will be used instead to ensure that the monitoring is done locally.\n",
        "    Evaluation: RAGAS will be used to evaluate the performance of the RAG pipeline since it is a simple and straightforward library to use.\n",
        "    User Interface: Chainlit UI will be used to create a user-friendly interface for the system. A more bespoke React UI will be used for the local deployment.\n",
        "    Server and Inference: FastAPI will be used to create a high-performance asynchronous API backend, while VLLM will optimize llama model inference through PagedAttention and continuous batching for maximum throughput and minimal latency.\n",
        "\n",
        "\n",
        "### Task 3: Dealing with the Data\n",
        "    a. Describe all of your data sources and external APIs, and describe what you’ll use them for.\n",
        "    b. Describe the default chunking strategy that you will use.  Why did you make this decision?\n",
        "    c. [Optional] Will you need specific data for any other part of your application?   If so, explain.\n",
        "\n",
        "\n",
        "[a] the data sources used in this project are pdf documents on magnesium alloy research:\n",
        "    - A Method for Comparing the Fatigue Performance of Forged AZ80 Magnesium, Andrew Gryguc et al.\n",
        "    - Application of Machine Learning Modeling in  Establishing the Process, Structure, and Property  Relationships of the Cast-Forged AZ80 Magnesium Alloy, Erfan Azqadan\n",
        "    - Characterization of forged magnesium alloys, Hamid Jahed et al.\n",
        "    - Fatigue of Forged AZ80 Magnesium Alloy, Andrew Gryguc\n",
        "    - Fatigue behaviour and fractography of extruded AZ80 magnesium alloys in very high cycle regime, Kazuaki Shiozawa et al.\n",
        "    - Microstructure and texture evolution during hot deformation of AZ80 magnesium alloy, Paresh Prakash\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Task 4: Building a Quick End-to-End Prototype\n",
        "    a. Build an end-to-end prototype and deploy it to a Hugging Face Space (or other endpoint)\n",
        "\n",
        "\n",
        "### Task 5: Creating a Golden Test Data Set\n",
        "    a. Assess your pipeline using the RAGAS framework including key metrics faithfulness, response relevance, context precision, and context recall.  Provide a table of your output results.\n",
        "    b. What conclusions can you draw about the performance and effectiveness of your pipeline with this information?\n",
        "\n",
        "[a] Original embedding model:\n",
        "    {'context_recall': 0.0208, 'faithfulness': 0.3642, 'factual_correctness': 0.3292, 'answer_relevancy': 0.7269, 'context_entity_recall': 0.0101, 'noise_sensitivity_relevant': 0.0371}\n",
        "\n",
        "    Fine-tuned embedding model:\n",
        "    {'context_recall': 0.0375, 'faithfulness': 0.3760, 'factual_correctness': 0.2842, 'answer_relevancy': 0.7266, 'context_entity_recall': 0.0038, 'noise_sensitivity_relevant': 0.0071}\n",
        "\n",
        "[b] Based on the RAGAS metrics for both pipeline implementations, several key conclusions can be drawn about their performance:\n",
        "\n",
        "        1. Low Context Recall (0.0375): Both pipelines struggle significantly with retrieving relevant context from the knowledge base, indicating that the retrieval mechanism may not be effectively identifying the most pertinent information for answering queries.\n",
        "\n",
        "        2. Poor Faithfulness (0.3760): The low faithfulness score suggests that the responses generated often contain information that cannot be directly supported by the retrieved context, raising concerns about hallucination and accuracy.\n",
        "\n",
        "        3. Weak Factual Correctness (0.2842): The low factual correctness score indicates that the responses may contain inaccurate or unreliable information, which is particularly concerning for a technical domain like magnesium alloy engineering.\n",
        "\n",
        "        4. Decent Answer Relevancy (0.7266): The relatively high answer relevancy score is a bright spot, showing that while the responses may not be entirely accurate, they are at least generally on-topic and addressing the user's query.\n",
        "\n",
        "        5. Very Poor Entity Recall (0.0038): The extremely low context entity recall suggests the system is failing to capture and incorporate specific technical terms, material properties, and other domain-specific entities in its responses.\n",
        "\n",
        "        6. Minimal Noise Sensitivity (0.0071): The low noise sensitivity score indicates that the system may be overly rigid in its responses and not adaptable enough to variations in user queries.\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "### Task 6: Fine-Tuning Open-Source Embeddings\n",
        "    a. Swap out your existing embedding model for the new fine-tuned version.  Provide a link to your fine-tuned embedding model on the Hugging Face Hub.\n",
        "\n",
        "\n",
        "### Task 7: Assessing Performance\n",
        "    a. How does the performance compare to your original RAG application?  Test the fine-tuned embedding model using the RAGAS frameworks to quantify any improvements.  Provide results in a table.\n",
        "    b. Articulate the changes that you expect to make to your app in the second half of the course. How will you improve your application?\n",
        "\n",
        "[a] The performance of the fine-tuned embedding model is better than the original embedding model, but in general the fine-tuning efforts did not yield any improvements, indicating a need to debug the pipeline.\n",
        "\n",
        "[b] advanced retrieval techniques, such as hybrid retrieval will be explored to improve the performance of the RAG pipeline."
      ],
      "metadata": {
        "id": "c9VLqpwnPvIT"
      }
    }
  ]
}